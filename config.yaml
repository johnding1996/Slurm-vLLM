# vLLM Slurm Job Configuration

1:
  model_name: "neuralmagic/Qwen2-0.5B-Instruct-FP8"
  number_of_jobs: 10
  gpu: "gpu:rtxa4000:1"